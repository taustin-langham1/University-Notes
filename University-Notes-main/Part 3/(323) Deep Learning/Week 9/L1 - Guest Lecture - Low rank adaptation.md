

- challenges on LL M's, power consumption, scaling issues 

PEFT, parameter efficient fine tuning

LoRA

less trainable parameters, faster training, lower resources, memory efficiency
we can cache trainable parameters in memory, eliminating the need for disk reads


